{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Numerical Digit Recognition on MNIST Dataset",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'digit-recognizer:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F3004%2F861823%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240213%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240213T085648Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da0b03bbdb9784aed145cd1c3e03b11e5b64efe4a398a29030a1efdb5ae3d92d106ebd0484abb031459e81ea556c3f1105be153b5084260378d0455f423631530ae02dc35c9ebc25cdd85907d4830c161ead8daa69b24ab410614affec738a42c07a55a4a00afad17f43b1133a994e6a058c29626b785deca79e7d587443c7e62c14bd82186f237e9e4ca2b03c48b3748d6e59c049aee2d338213649e27065509c905c2cce143f78d5dbe57d3f129d19f059c8ce52275071d733b6ef789e13f3f0667e22357f640bd094fc93fd6444b58711568e0940baa856c888c36d22621c40572a3707cde60442a6a14b318ea9d34ffd44dc4d80fb0e96329745f64a1bd2d'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "tkGc7Ec2rOFl"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Numerical Digit Recognition using CNN**"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "TPaRjNx8rOFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hi Kaggle Fellows,\n",
        "This is my first try on Deep Learning model. Many more to come. I hope this will help all the beginners and I'm waiting to here from you all. Thanking you all in advance for the feedbacks and suggestions."
      ],
      "metadata": {
        "id": "lBr5z6S6rOFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 1: Importing Required Libraries**"
      ],
      "metadata": {
        "id": "GJi1tsF4rOFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries for data preprocessing and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "sns.set(style='white', context='notebook', palette='deep')\n",
        "\n",
        "\n",
        "np.random.seed(2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:34.652184Z",
          "iopub.execute_input": "2023-02-24T09:27:34.652781Z",
          "iopub.status.idle": "2023-02-24T09:27:34.658919Z",
          "shell.execute_reply.started": "2023-02-24T09:27:34.652744Z",
          "shell.execute_reply": "2023-02-24T09:27:34.657924Z"
        },
        "trusted": true,
        "id": "zOWowc3NrOFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"np.random.seed(2)\" sets the seed of the NumPy random number generator to 2.\n",
        "The NumPy random number generator is a pseudorandom number generator that produces a sequence of numbers that appears random but is actually determined by an initial seed value. Setting the seed to a specific value ensures that the same sequence of random numbers is generated every time the code is run, which can be useful for debugging and testing purposes."
      ],
      "metadata": {
        "id": "r9oTGqu-rOFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries for data splitting and confusion matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "import itertools"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:34.660369Z",
          "iopub.execute_input": "2023-02-24T09:27:34.660972Z",
          "iopub.status.idle": "2023-02-24T09:27:34.676167Z",
          "shell.execute_reply.started": "2023-02-24T09:27:34.660935Z",
          "shell.execute_reply": "2023-02-24T09:27:34.675126Z"
        },
        "trusted": true,
        "id": "rGday2_9rOFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The itertools module is a standard library module in Python that provides various functions for creating iterators and generators for efficient looping. It contains a collection of tools that allow you to work with sequences, iterators, and functions that return iterators."
      ],
      "metadata": {
        "id": "_1yt_Oo5rOFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries for deep learning\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:34.67919Z",
          "iopub.execute_input": "2023-02-24T09:27:34.679848Z",
          "iopub.status.idle": "2023-02-24T09:27:34.687754Z",
          "shell.execute_reply.started": "2023-02-24T09:27:34.679773Z",
          "shell.execute_reply": "2023-02-24T09:27:34.686853Z"
        },
        "trusted": true,
        "id": "G1D43i3OrOFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. \"from keras.utils.np_utils import to_categorical\" - Import a function from Keras to convert numerical labels to one-hot encoded categorical labels.\n",
        "2. \"from keras.models import Sequential\" - Import the Sequential model from Keras for building a linear stack of layers.\n",
        "3. \"from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\" - Import various layer types from Keras for constructing a neural network architecture.\n",
        "4. \"from keras.optimizers import RMSprop\" - Import the RMSprop optimizer from Keras for training a neural network.\n",
        "5. \"from keras.preprocessing.image import ImageDataGenerator\" - Import the ImageDataGenerator class from Keras for generating batches of image data with data augmentation.\n",
        "6. \"from keras.callbacks import ReduceLROnPlateau\" - Import the ReduceLROnPlateau callback from Keras for reducing the learning rate during training when the validation loss plateaus."
      ],
      "metadata": {
        "id": "mKAnzboFrOFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 2: Data Preprocessing**"
      ],
      "metadata": {
        "id": "W3TJuFwyrOFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset\n",
        "train = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n",
        "test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:34.689693Z",
          "iopub.execute_input": "2023-02-24T09:27:34.690152Z",
          "iopub.status.idle": "2023-02-24T09:27:37.950113Z",
          "shell.execute_reply.started": "2023-02-24T09:27:34.690095Z",
          "shell.execute_reply": "2023-02-24T09:27:37.949108Z"
        },
        "trusted": true,
        "id": "6zxwnTJZrOFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Viewing the dataset\n",
        "train.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:37.951415Z",
          "iopub.execute_input": "2023-02-24T09:27:37.951796Z",
          "iopub.status.idle": "2023-02-24T09:27:37.972922Z",
          "shell.execute_reply.started": "2023-02-24T09:27:37.951757Z",
          "shell.execute_reply": "2023-02-24T09:27:37.971916Z"
        },
        "trusted": true,
        "id": "QWIaD5FJrOFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the features and output for training data\n",
        "X_train = train.drop(labels = [\"label\"],axis = 1)\n",
        "y_train = train[\"label\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:37.97432Z",
          "iopub.execute_input": "2023-02-24T09:27:37.974793Z",
          "iopub.status.idle": "2023-02-24T09:27:38.063013Z",
          "shell.execute_reply.started": "2023-02-24T09:27:37.974753Z",
          "shell.execute_reply": "2023-02-24T09:27:38.061778Z"
        },
        "trusted": true,
        "id": "1wbNhldzrOFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for null values\n",
        "#Training data\n",
        "train.isnull().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:38.064815Z",
          "iopub.execute_input": "2023-02-24T09:27:38.065399Z",
          "iopub.status.idle": "2023-02-24T09:27:38.112933Z",
          "shell.execute_reply.started": "2023-02-24T09:27:38.065359Z",
          "shell.execute_reply": "2023-02-24T09:27:38.111795Z"
        },
        "trusted": true,
        "id": "U_DA7yePrOF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data\n",
        "test.isnull().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:38.114528Z",
          "iopub.execute_input": "2023-02-24T09:27:38.115139Z",
          "iopub.status.idle": "2023-02-24T09:27:38.149292Z",
          "shell.execute_reply.started": "2023-02-24T09:27:38.115102Z",
          "shell.execute_reply": "2023-02-24T09:27:38.148215Z"
        },
        "trusted": true,
        "id": "3bUfrAgBrOF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no null values"
      ],
      "metadata": {
        "id": "oCfeDC6ArOF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalization\n",
        "X_train = X_train / 255.0\n",
        "test = test / 255.0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:38.150983Z",
          "iopub.execute_input": "2023-02-24T09:27:38.151354Z",
          "iopub.status.idle": "2023-02-24T09:27:38.326923Z",
          "shell.execute_reply.started": "2023-02-24T09:27:38.151319Z",
          "shell.execute_reply": "2023-02-24T09:27:38.325833Z"
        },
        "trusted": true,
        "id": "rsCZ1ZC-rOF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Done the above step because, CNN converg faster on [0....1] data than on [0....255]. Also, I performed a grayscale normalization to reduce the effect of illumination's differences."
      ],
      "metadata": {
        "id": "r54yCfzMrOF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
        "X_train = X_train.values.reshape(-1,28,28,1)\n",
        "test = test.values.reshape(-1,28,28,1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:38.328562Z",
          "iopub.execute_input": "2023-02-24T09:27:38.328992Z",
          "iopub.status.idle": "2023-02-24T09:27:38.334565Z",
          "shell.execute_reply.started": "2023-02-24T09:27:38.328943Z",
          "shell.execute_reply": "2023-02-24T09:27:38.333369Z"
        },
        "trusted": true,
        "id": "Z31y3L6WrOF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Train and test images (28px x 28px) are as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices. But Keras requires an extra dimension in the end which correspond to RGB channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we should reshape 784px vectors to 28x28x3 3D matrices."
      ],
      "metadata": {
        "id": "e6fChmGTrOF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoding\n",
        "#Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
        "y_train = to_categorical(y_train, num_classes = 10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:38.335998Z",
          "iopub.execute_input": "2023-02-24T09:27:38.337042Z",
          "iopub.status.idle": "2023-02-24T09:27:38.346431Z",
          "shell.execute_reply.started": "2023-02-24T09:27:38.337006Z",
          "shell.execute_reply": "2023-02-24T09:27:38.345497Z"
        },
        "trusted": true,
        "id": "wKpdzjHsrOF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the trainng dataset as for training and the validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:38.349577Z",
          "iopub.execute_input": "2023-02-24T09:27:38.350631Z",
          "iopub.status.idle": "2023-02-24T09:27:38.725459Z",
          "shell.execute_reply.started": "2023-02-24T09:27:38.350604Z",
          "shell.execute_reply": "2023-02-24T09:27:38.724395Z"
        },
        "trusted": true,
        "id": "kgUl7NlirOF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"stratify = True\" ensures that the distribution of the target variable is approximately the same in both the training and test datasets."
      ],
      "metadata": {
        "id": "fwMNwx1BrOF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing an example for better understanding the images in our dataset\n",
        "g = plt.imshow(X_train[8][:,:,0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:38.726786Z",
          "iopub.execute_input": "2023-02-24T09:27:38.727789Z",
          "iopub.status.idle": "2023-02-24T09:27:38.994725Z",
          "shell.execute_reply.started": "2023-02-24T09:27:38.727746Z",
          "shell.execute_reply": "2023-02-24T09:27:38.993827Z"
        },
        "trusted": true,
        "id": "2NPhYitErOF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 3: CNN - Convolution Neural Networks**"
      ],
      "metadata": {
        "id": "8cDx7sd6rOF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the CNN model\n",
        "#CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation = \"softmax\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:38.99611Z",
          "iopub.execute_input": "2023-02-24T09:27:38.996557Z",
          "iopub.status.idle": "2023-02-24T09:27:39.074169Z",
          "shell.execute_reply.started": "2023-02-24T09:27:38.996521Z",
          "shell.execute_reply": "2023-02-24T09:27:39.073164Z"
        },
        "trusted": true,
        "id": "voRIo27lrOF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Convolutional Neural Network (CNN) model using the Keras API with the following architecture:\n",
        "\n",
        "1. Input layer: a 2D convolutional layer with 32 filters, a kernel size of (5, 5), and a ReLU activation function. The input shape is (28, 28, 1), representing a grayscale image with dimensions 28x28 pixels.\n",
        "2. Hidden layer 1: a 2D convolutional layer with 32 filters, a kernel size of (5, 5), and a ReLU activation function. Padding is set to 'Same' to ensure the output size matches the input size.\n",
        "3. Max pooling layer 1: a 2D max pooling layer with a pool size of (2, 2) and a stride of (2, 2). This layer reduces the spatial dimensions of the output from the previous layer by a factor of 2, helping to reduce overfitting.\n",
        "4. Dropout layer 1: a dropout layer with a rate of 0.25, which randomly drops out 25% of the input units during training to further prevent overfitting.\n",
        "5. Hidden layer 2: a 2D convolutional layer with 64 filters, a kernel size of (3, 3), and a ReLU activation function.\n",
        "6. Hidden layer 3: a 2D convolutional layer with 64 filters, a kernel size of (3, 3), and a ReLU activation function. Padding is set to 'Same' to ensure the output size matches the input size.\n",
        "7. Max pooling layer 2: a 2D max pooling layer with a pool size of (2, 2) and a stride of (2, 2). This layer reduces the spatial dimensions of the output from the previous layer by a factor of 2.\n",
        "8. Dropout layer 2: a dropout layer with a rate of 0.25.\n",
        "9. Flatten layer: a layer that flattens the output from the previous layer into a 1D array.\n",
        "10. Fully connected layer: a fully connected layer with 256 units and a ReLU activation function.\n",
        "11. Dropout layer 3: a dropout layer with a rate of 0.5.\n",
        "12. Output layer: a fully connected layer with 10 units and a softmax activation function, which outputs a probability distribution over the 10 classes (digits 0-9)."
      ],
      "metadata": {
        "id": "bRM3dCTArOF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'relu' is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network."
      ],
      "metadata": {
        "id": "AIZHRK4ErOF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the Optimizer\n",
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:39.077356Z",
          "iopub.execute_input": "2023-02-24T09:27:39.077635Z",
          "iopub.status.idle": "2023-02-24T09:27:39.084067Z",
          "shell.execute_reply.started": "2023-02-24T09:27:39.077609Z",
          "shell.execute_reply": "2023-02-24T09:27:39.082592Z"
        },
        "trusted": true,
        "id": "_B18NxA_rOF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimizer is responsible for adjusting the weights and biases of the network during training in order to minimize the error or loss function. The annealer, on the other hand, is responsible for adjusting the learning rate of the optimizer during training. The learning rate determines the size of the steps taken by the optimizer when updating the weights and biases of the network. A high learning rate can cause the optimizer to overshoot the minimum of the loss function, while a low learning rate can cause the optimizer to take too long to converge to the minimum."
      ],
      "metadata": {
        "id": "7L9c2QQGrOF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the model\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:39.085373Z",
          "iopub.execute_input": "2023-02-24T09:27:39.086999Z",
          "iopub.status.idle": "2023-02-24T09:27:39.097766Z",
          "shell.execute_reply.started": "2023-02-24T09:27:39.086961Z",
          "shell.execute_reply": "2023-02-24T09:27:39.096759Z"
        },
        "trusted": true,
        "id": "hAyQHKN8rOF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train our neural network model, we must set up a score function, a loss function, and an optimization algorithm. The loss function measures the discrepancy between the predicted and true labels for labeled images, and for categorical classifications with more than two classes, we use the \"categorical_crossentropy\" form of the loss function.\n",
        "The optimizer is a crucial component of the training process, as it iteratively updates the parameters of the model (e.g. filters, kernel values, weights, and biases of neurons) to minimize the loss function. For this particular model, we have selected RMSprop as our optimizer, with default values. RMSprop is an effective optimizer that adjusts the Adagrad method in a simple way to reduce its aggressive, monotonically decreasing learning rate. Alternatively, we could have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop."
      ],
      "metadata": {
        "id": "oVJInCkbrOF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the Annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:39.105237Z",
          "iopub.execute_input": "2023-02-24T09:27:39.105636Z",
          "iopub.status.idle": "2023-02-24T09:27:39.112043Z",
          "shell.execute_reply.started": "2023-02-24T09:27:39.105608Z",
          "shell.execute_reply": "2023-02-24T09:27:39.11101Z"
        },
        "trusted": true,
        "id": "db14zx2DrOF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the speed and accuracy of the optimizer in finding the global minimum of the loss function, an annealing method of the learning rate (LR) was used.\n",
        "The LR determines the step size that the optimizer takes while traversing the 'loss landscape'. A higher LR results in larger steps and faster convergence, but poor sampling and a higher likelihood of falling into a local minima.\n",
        "To efficiently reach the global minimum of the loss function, it is better to have a decreasing LR during training. However, to maintain fast computation time with a high LR, the LR was decreased dynamically every X steps (epochs) only if necessary, i.e., when accuracy did not improve.\n",
        "The Keras.callbacks ReduceLROnPlateau function was used to reduce the LR by half if the accuracy did not improve after 3 epochs."
      ],
      "metadata": {
        "id": "iiTDtfoErOF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "batch_size = 86"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:39.113353Z",
          "iopub.execute_input": "2023-02-24T09:27:39.114441Z",
          "iopub.status.idle": "2023-02-24T09:27:39.121746Z",
          "shell.execute_reply.started": "2023-02-24T09:27:39.114404Z",
          "shell.execute_reply": "2023-02-24T09:27:39.120722Z"
        },
        "trusted": true,
        "id": "aWavsoOBrOF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model will train for 1 epoch with a batch size of 86. To achieve a higher accuracy of 0.9967, the number of epochs should be increased to 30."
      ],
      "metadata": {
        "id": "Dj3XTwGxrOF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model to the training set\n",
        "history = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = (X_val, y_val), verbose = 2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:39.124377Z",
          "iopub.execute_input": "2023-02-24T09:27:39.124672Z",
          "iopub.status.idle": "2023-02-24T09:27:45.300765Z",
          "shell.execute_reply.started": "2023-02-24T09:27:39.124647Z",
          "shell.execute_reply": "2023-02-24T09:27:45.299656Z"
        },
        "trusted": true,
        "id": "6ziDIA5orOF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 4: Evaluation**"
      ],
      "metadata": {
        "id": "xC29DoIarOF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CONFUSION MATRIX\n",
        "\n",
        "#Defining a function for confusion matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "#Predicting the values from the validation dataset\n",
        "y_pred = model.predict(X_val)\n",
        "#Converting predictions classes to one hot vectors\n",
        "y_pred_classes = np.argmax(y_pred,axis = 1)\n",
        "#Converting validation observations to one hot vectors\n",
        "y_true = np.argmax(y_val,axis = 1)\n",
        "#Computing the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
        "#Plotting the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(10))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:45.30471Z",
          "iopub.execute_input": "2023-02-24T09:27:45.305043Z",
          "iopub.status.idle": "2023-02-24T09:27:46.897367Z",
          "shell.execute_reply.started": "2023-02-24T09:27:45.305013Z",
          "shell.execute_reply": "2023-02-24T09:27:46.896345Z"
        },
        "trusted": true,
        "id": "TIy4U4ZFrOF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To display some error results\n",
        "\n",
        "errors = (y_pred_classes - y_true != 0)\n",
        "\n",
        "y_pred_classes_errors = y_pred_classes[errors]\n",
        "y_pred_errors = y_pred[errors]\n",
        "y_true_errors = y_true[errors]\n",
        "X_val_errors = X_val[errors]\n",
        "\n",
        "#Defining a function for plotting the erros results\n",
        "def display_errors(errors_index, img_errors, pred_errors, obs_errors):\n",
        "    \"\"\" This function shows 12 images with their predicted and real labels\"\"\"\n",
        "    nrows = 4\n",
        "    ncols = 3\n",
        "    fig, ax = plt.subplots(nrows, ncols, figsize=(10, 10))\n",
        "    fig.subplots_adjust(hspace=0.5)\n",
        "    for i, axi in enumerate(ax.flat):\n",
        "        if i < len(errors_index):\n",
        "            error = errors_index[i]\n",
        "            axi.imshow((img_errors[error]).reshape((28,28)))\n",
        "            axi.set_title(\"Predicted label: {}\\nTrue label: {}\".format(pred_errors[error], obs_errors[error]))\n",
        "        axi.set_xticks([])\n",
        "        axi.set_yticks([])\n",
        "\n",
        "# Probabilities of the wrong predicted numbers\n",
        "y_pred_errors_prob = np.max(y_pred_errors, axis=1)\n",
        "\n",
        "# Predicted probabilities of the true values in the error set\n",
        "true_prob_errors = np.diagonal(np.take(y_pred_errors, y_true_errors, axis=1))\n",
        "\n",
        "# Difference between the probability of the predicted label and the true label\n",
        "delta_pred_true_errors = y_pred_errors_prob - true_prob_errors\n",
        "\n",
        "# Sorted list of the delta prob errors\n",
        "sorted_delta_errors = np.argsort(delta_pred_true_errors)\n",
        "\n",
        "# Top 12 errors\n",
        "most_important_errors = sorted_delta_errors[-12:]\n",
        "\n",
        "# Displaying the top 12 errors\n",
        "display_errors(most_important_errors, X_val_errors, y_pred_classes_errors, y_true_errors)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:46.901371Z",
          "iopub.execute_input": "2023-02-24T09:27:46.904386Z",
          "iopub.status.idle": "2023-02-24T09:27:47.638911Z",
          "shell.execute_reply.started": "2023-02-24T09:27:46.90434Z",
          "shell.execute_reply": "2023-02-24T09:27:47.637909Z"
        },
        "trusted": true,
        "id": "Hw6feyL_rOF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the results\n",
        "results = model.predict(test)\n",
        "\n",
        "# selecting the indix with the maximum probability\n",
        "results = np.argmax(results,axis = 1)\n",
        "\n",
        "results = pd.Series(results,name=\"Label\")\n",
        "results"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:27:47.640191Z",
          "iopub.execute_input": "2023-02-24T09:27:47.640839Z",
          "iopub.status.idle": "2023-02-24T09:27:49.964276Z",
          "shell.execute_reply.started": "2023-02-24T09:27:47.640801Z",
          "shell.execute_reply": "2023-02-24T09:27:49.963289Z"
        },
        "trusted": true,
        "id": "405SPxj9rOF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
        "submission.to_csv(\"submission.csv\",index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T09:32:39.0983Z",
          "iopub.execute_input": "2023-02-24T09:32:39.098705Z",
          "iopub.status.idle": "2023-02-24T09:32:39.136574Z",
          "shell.execute_reply.started": "2023-02-24T09:32:39.098671Z",
          "shell.execute_reply": "2023-02-24T09:32:39.13567Z"
        },
        "trusted": true,
        "id": "m2gpO5sorOF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqQaNDlfrOF7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}